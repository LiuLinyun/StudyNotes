# 概率论与数理统计

## 1.随机事件及其概率

### 1.2.随机事件

#### 1.2.1 随机事件的定义

定义：

* 试验可以在相同条件下重复进行；
* 每次试验可能结果不止一个，并且试验前可以确定所有可能出现的结果；
* 每次试验之前不能准确预言出哪一个结果会出现。

具有以上三个特征的试验称为随机试验。

#### 1.2.2 样本空间

将随机试验 $E$ 中可能出现的基本结果称为样本点，一般用小写字母 $w,e$ 等表示，由所有样本点组成的集合称为 $E$ 的样本空间，记为 $\varOmega$。

#### 1.2.3 样本空间的集合表示

我们用样本空间 $\varOmega$ 中的子集代表随机事件 $A$，也可以记为基本样本点的一个集合，如 $A=\{w_1,w_2,w_3 \}$。

#### 1.2.4 事件之间的关系及运算

1. **子事件**：如果事件 $A$ 的样本点也属于事件 $B$，则称 $A$ 为 $B$ 的子事件。记为 $A \subset B$。如果事件 $A$ 与 $B$ 互为子事件，则称事件 $A$ 与 $B$ 相等，记为 $A = B$。
2. **和事件**:
3. **积事件**
4. **互斥事件与对立事件**
5. **差事件**
6. **完备事件组**

#### 1.2.5 事件的运算法则

### 1.3 事件的概率

#### 1.3.3 古典概率

设事件 $E$ 的样本空间 $\varOmega$ 由 $n$ 个样本点组成，毎个样本点等可能发生，事件 $A$ 由 $r$ 个样本点组成，则定义事件 $A$ 的概率为 $\dfrac r n$，记为 $P(A)$，即

$$P(A) = \dfrac {\text{A中样本点数} } {\varOmega \text{中样本点数} }   = \dfrac r n$$

#### 1.3.4 几何概率

设随机事件 $E$ 的样本空间 $\varOmega$ 为可测（有界）的区域，事件 $A$ 可以用 $\varOmega$ 中的子区域 $A$ 表示，即样本点落在区域 $A$ 中，表明事件 $A$ 发生。如果事件 $A$ 出现的可能性与该区域的几何测度有关，而与该区域的位置和形状无关，则称随机事件 $E$ 为几何概率，并定义 $A$ 的几何概率为

$$P(A) = \dfrac {A 的几何测度 } {\varOmega 的几何测度}$$

### 1.4 条件概率

#### 1.4.1 条件概率的定义

条件概率是指在某事件 $A$ 已经发生的情况下，事件 $B$ 发生的概率，记为 $P(B|A)$。设 $A,B$ 是样本空间 $\varOmega$ 中的两个随机事件，如果 $P(A)>0$，则称 $\dfrac {P(AB)} {P(A)}$ 为事件 $A$ 发生的条件下事件 $B$ 发生的 **条件概率**，记为 $P(B|A)$，即

$$P(B|A) = \dfrac {P(AB)} {P(A)}$$

#### 1.4.2 乘法公式

设两个随机事件 $A,B$，如果 $P(A)>0,P(B)>0$，则

$$P(AB) = P(A)P(B|A) = P(B)P(A|B)$$

被称为乘法公式。

意思是：$A,B$ 两个事件乘积的概率，也就是同时发生的概率，等于先求事件 $A$ 发生的概率，再乘以事件 $B$ 在事件 $A$ 已发生条件下的概率。

#### 1.4.3 全概率公式

设事件 $A_1,A_2,\dots,A_n$ 是两两互斥的， $P(A_i) > 0,i=1,2,\dots,n$，事件 $B$ 满足关系 $B \subset \displaystyle \bigcup_{i=1}^n A_i$，则事件 $B$ 的概率计算有如下公式：

$$P(B) = \sum_{i=1}^n P(A_i)P(B|A_i)$$

上式被称为全概率公式。

意思是：欲求一个复杂事件 $B$ 的概率，可以用一组完备事件 $A_1,A_2,\dots,A_n$ 对 $B$ 进行剖分，先求 $B$ 在毎个 $A_i$ 条件下的概率 $P(B|A_i)$，再对条件概率以 $P(A_i)$ 为权值加权求和。

#### 1.4.4 贝叶斯公式

设事件 $A_1,A_2,\dots,A_n$ 是两两互斥的， $P(A_i) > 0,i=1,2,\dots,n$，事件 $B$ 满足关系 $B \subset \displaystyle \bigcup_{i=1}^n A_i$，且 $P(B)>0$，则在事件 $B$ 发生的条件下，各个事件 $A_k$ 发生的概率为

$$P(A_k|B) = \dfrac {P(A_kB)} {P(B)} = \dfrac {P(A_k)P(B|A_k)} {\displaystyle \sum_{i=1}^n P(A_i)P(B|A_i)}, \quad k=1,2,\dots,n$$

贝叶斯公式描述了一种由“结果”到“原因”的关系，反映出了当前事件发生下，引起该事件发生的原因的可能性。

### 1.5 事件的独立性

#### 1.5.1 两个事件的独立性

设 $A,B$ 为两个随机事件，如果

$$P(AB) = P(A)P(B)$$

则称事件 $A$ 与 $B$ 相互独立。

**Tip**：两事件 $A,B$ 的独立性与两事件 $A,B$ 的互斥是两个不同的概念，不要混淆。如 $A \subset \varOmega$，事件 $A$ 与 $\varOmega$ 是相互独立的，但是并不是互斥的。

#### 1.5.3 独立重复试验，二项概率公式

随机试验的独立性：设有两个随机试验 $E_1,E_2$，假如试验 $E_1$ 的任意一个结果（事件）与试验 $E_2$ 的任意一个结果（事件）都是相互独立的，则称这两个试验是相互独立的。

$n$ 重独立试验：如果有 $n$ 个相同的且相互独立的试验 $E_1,E_2,\dots,E_n$，则称这 $n$ 次试验为 $n$ 次独立重复试验或 $n$ 重独立试验。

伯努利试验：在试验 $E$ 中，如果试验的可能结果只有两个，或事件 $A$ 出现，或事件 $\overline A$ 出现，则称试验 $E$ 为伯努利试验，一般记事件 $A$ 出现的概率为 $p$，事件 $\overline A$ 出现的概率为 $1-p$。

二项概率公式：在 $n$ 重伯努利试验中，事件 $A$ 发生 $k$ 次（$0 \leqslant k \leqslant n$）的概率记为 $P_n(k)$，则

$$P_n(k) = \mathrm C_n^k p^k(1-p)^{n-k}$$

## 2.一维随机变量及其分布

### 2.1 随机变量及其分布函数

#### 2.1.1 随机变量

有些随机试验的可能结果都与数量有关，我们可以将随机试验的可能结果用不同的数值表示。如抛硬币试验中，用数“1”表示“正面出现”，数“2”表示“反面出现”，这样就可以把这个随机试验的结果是“1”或者“0”，若记 $w_1 = \{反面出现\},w_2=\{正面出现\}$，则这个试验的样本空间为 $\varOmega = \{ w_1,w_2 \}$，那么上述试验的结果的数值变化可以用下列单实值函数来描述：

$$X(w) = \begin{cases} 0, w=w_1 \\ 1, w=w_2 \end{cases}$$

显然，单实值函数 $X$ 是一个取值具有随机性的变量，称 $X$ 为随机变量。更加一般性的描述如下：

设 $\varOmega$ 为随机试验 $E$ 上的一个样本空间，$X$ 为 $\varOmega$ 上的一个单实值函数，若满足对任意的 $x \in \mathrm R$，有 $\{x \leqslant x\} = \{w|X(w) \leqslant x, w \in \varOmega \} \in \mathscr F$，其中 $\mathscr F$ 是事件域。则称 $X$ 为概率空间 $(\varOmega, \mathscr F,P)$ 上的随机变量。

#### 2.1.2 分布函数的定义

设 $X$ 为一个随机变量，对任意实数 $x$，$\{X \leqslant \}$ 都是事件，我们可以求出它的概率 $ P\{X \leqslant x\}$，这个概率显然是 $x$ 的函数，它的值随 $x$ 的变化而变化。记

$$ F(x) = P\{X \leqslant x\}, \quad x \in \mathbf R $$

为 $X$ 的分布函数。

分布函数完整地给出了随机变量的统计规律性。

### 2.2 离散型随机变量及其分布

#### 2.2.1离散型随机变量及其分布律

如果随机变量 $X$ 取有有限多个或者可列多个不同的值，则称 $X$ 为离散型随机变量。

设 $X$ 为一个离散型随机变量，它的所有可能取值为 $a_1,a_2,a_3,\dots$， 则称概率 $p_i = P\{X=a_i\}，i=1,2,3,\dots$ 为 $X$ 的分布律或者概率分布。

$X$ 的分布函数 $F(x)$ 与 $X$ 的分布律 $p_i(i=1,2,\dots)$ 有如下关系

$$\begin{aligned} F(x) = \sum_{a_i \leqslant x} P\{X=a_i\}, \quad x \in \mathbf R \\
P\{X=a_i\} = F(a_i) - F(a_i - 0)
\end{aligned}$$

#### 2.2.2 常见离散型随机变量的分布律

1. 退化分布
2. 两点分布
3. 二项分布
4. 泊松分布
5. 几何分布
6. 负二项分布
7. 超几何分布

### 2.3 连续型随机变量及其分布

#### 2.3.1 连续型随机变量及其密度函数

设 $F(x)$ 为随机变量 $X$ 的分布函数，如果 $F(x)$ 可表示为非负函数 $f(x)$ 的积分，

$$ F(x) = \int_{-\infty}^x f(t)\mathrm dt, \quad x\in \mathbf R$$

则称 $x$ 为连续型随机变量。称 $f(x)$ 为 $X$ 的密度函数，简称为密度。称 $F(x)$ 为连续型分布函数。

注意：因为连续型随机变量 $X$ 的分布函数 $F(x)$ 关于 $x$ 是处处连续的，所以对于任意实数 $x$，有 $P\{X=x\} = F(x) - F(x-0) = 0$。由此可见，**概率为 0 的事件不一定是不可能事件，概率为 1 的事件也不一定是必然事件**。

#### 2.3.2 常见的连续型随机变量的密度函数

1. 均匀分布
2. 指数分布
3. 正态分布

### 2.4 随机变量函数的分布

#### 2.4.1 离散型随机变量函数的分布

离散型随机变量 $X$ 的函数 $g(X)$ 显然仍然是离散型随机变量，首先根据 $X$ 的所有可能取值求出 $g(X)$ 的所有可能取值，然后通过 $X$ 的分布律用列表法或分析法导出 $g(X)$ 的分布律。

#### 2.4.2 连续型随机变量函数的分布

如果连续型随机变量的函数仍然为连续型随机变量，我们先使用分布函数法先求出 $Y=g(X)$ 的分布 $F_Y(y)$，再对 $F_Y(y)$ 求导得到密度函数 $f_Y(y)$。

## 3.多维随机变量及其分布

### 3.1 二维随机变量及其分布函数

#### 3.1.1 二维随机变量及其分布函数

设 $\varOmega$ 是随机试验 $E$ 的样本空间，$X,Y$ 是定义在 $\varOmega$ 上的两个随机变量，则由 $X$ 和 $Y$ 构成的二维向量 $(X,Y)$ 称为 $\varOmega$ 上的二维随机变量或随机向量。

设 $(X,Y)$ 是二维随机变量，$x,y$ 是任意两个实数，则

$$ \{ X \leqslant x, Y \leqslant y\} = \{ w|X(w) \leqslant x 且 Y(w) \leqslant y, w \in \varOmega \}$$

是随机事件，且有

$$\{ X \leqslant x, Y \leqslant y\} = \{ X \leqslant x\} \cap \{ Y \leqslant y\} $$

设 $(X,Y)$ 为二维随机变量，对于任意实数 $x,y$ 记

$$F(x,y) = P\{X\leqslant x,Y\leqslant y\}$$

称 $F(x,y)$ 为二维随机变量 $(X,Y)$ 的联合分布函数，简称分布函数。

#### 3.1.2 二维离散型随机变量及其分布律

如果二维随机变量 $(X,Y)$ 的所有可能取值是有限个数对或可数多个数对，则称 $(X,Y)$ 是二维离散型随机变量。

设二维离散型随机变量 $(X,Y)$ 所有可能取值为 $\{ (a_i,b_j),\quad i,j = 1,2,\dots\}$ 且

$$P\{X=a_i,Y=b_j \} = p_{ij}, \quad i,j=1,2,\dots $$

则称 $p_{ij}$ 为二维离散型随机变量 $(X,Y)$ 的联合分布律或概率分布，简称为 $(X,Y)$ 的分布律。

二维离散型随机变量的联合分布函数和分布律有如下关系：

$$ \begin{aligned} F(x,y) & = \sum_{a_i \leqslant x, b_j \leqslant y} P\{X=a_i,Y=b_j\} \\
P\{X=a_i,Y=b_j\} & = F(a_i,b_j) - F(a_i,b_j-0)-F(a_i-0,b_j)+F(a_i-0,b_j-0)\end{aligned}$$

#### 3.1.3 二维连续型随机变量及其密度函数

设二维随机变量 $(X,Y)$ 的分布函数为 $F(x,y)$，如果存在非负二元可积函数 $f(x,y)$，使得对任意的实数 $x,y$，有

$$F(x,y) = \int_{-\infty}^x \int_{-\infty}^y f(u,v) \mathrm d u \mathrm d v$$

则称 $(X,Y)$ 是二维连续型随机变量，称函数 $f(x,y)$ 为 $(X,Y)$ 的联合密度函数，简称为密度函数。

### 3.2 边缘分布与随机变量的独立性

#### 3.2.1 边缘分布函数

边缘分布相对于联合分布而言，是指 $n(n\geqslant 2)$ 维随机变量的部分随机变量的分布，如二维随机变量 $(X,Y)$，边缘分布就是 $X$ 和 $Y$ 各自的概率分布。

$$\begin{aligned} F_X(x) = P(X \leqslant x) = P\{X\leqslant x,Y<+\infty\} = F(x,+\infty) \\
F_Y(y) = P(Y \leqslant y) = P\{X<+\infty,Y\leqslant y\} = F(+\infty,y)\end{aligned}$$

#### 3.2.2 边缘分布律

#### 3.2.3 边缘密度函数

设二维连续型随机变量 $(X,Y)$ 具有联合密度函数 $f(x,y)$，因为

$$\begin{aligned} F_X(x) = F(x, + \infty) = \int_{-\infty}^x \mathrm d x \int_{-\infty}^{+\infty} f(x,y) \mathrm d y = \int_{-\infty}^x f_X(x) \mathrm d x \\
F_Y(y) = F(+ \infty,y) = \int_{-\infty}^y \mathrm d y \int_{-\infty}^{+\infty} f(x,y) \mathrm d x = \int_{-\infty}^y f_Y(y) \mathrm d y\end{aligned}$$

其中

$$\begin{aligned} f_X(x) = \int_{-\infty}^{+\infty} f(x,y) \mathrm d y, \quad x \in \mathbf R \\
f_Y(y) = \int_{-\infty}^{+\infty} f(x,y) \mathrm d x, \quad y \in \mathbf R \end{aligned}$$

称 $f_X(x),f_Y(y)$ 分别为 $X$ 和 $Y$ 的边缘密度函数，即为 $(X,Y)$ 的边缘密度函数。

#### 3.2.4 两个随机变量间的独立性

设 $F(x,y)$ 及 $F_X(x), F_Y(y)$ 分别是二维随机变量 $(X,Y)$ 的联合分布函数及边缘分布函数，如果对任意实数 $x,y$ 有

$$P\{ X \leqslant x, Y \leqslant y\} = P\{ X \leqslant x\} \cdot P\{ Y \leqslant y\}$$

即

$$F(x,y) = F_X(x) \cdot  F_Y(y)$$

成立，则称随机变量 $X$ 和 $Y$ 相互独立。

当 $(X,Y)$ 是离散型随机变量时，$X$ 和 $Y$ 相互独立的条件等价于对所有 $(X,Y)$ 的可能取值 $(a_i,b_j)$，均有

$$P\{X=a_i,Y=b_j\} = P\{X=a_i\} \cdot P\{Y=b_j\}$$

当 $(X,Y)$ 是连续型随机变量时，$X$ 和 $Y$ 相互独立的条件等价于在联合密度函数的任意连续点 $(x,y)$，均有

$$f(x,y) = f_X(x) \cdot f_Y(y)$$

### 3.4 二维随机变量函数的分布

#### 3.4.1 二维离散型随机变量函数的分布

对于二维离散型随机变量 $(X,Y)$，当 $g(X,Y)$ 是二元连续函数时，其函数值 $Z=g(X,Y)$ 是一维离散型随机变量。当 $(X,Y)$ 的联合分布律已知时，求其函数 $Z=g(X,Y)$ 的分布律，主要方法有列表计算法和归纳分析法。

#### 3.4.2 二维连续型随机变量函数的分布

对于二维连续型随机变量 $(X,Y)$，当 $g(X,Y)$ 是二元连续函数时，其函数 $Z=g(X,Y)$ 是一维连续型随机变量。当 $(X,Y)$ 的联合密度函数已知时，求其函数 $Z=g(X,Y)$ 的密度函数。具体做法是：先求分布函数 $F_Z(z) = P\{g(X,Y) \leqslant z\}$，通过 $F_Z'(z)$ 再求密度函数 $f_Z(z)$。

## 4.随机变量的数字特征

### 4.1 常见的数字特征

1. 数学期望（均值）
2. 方差
3. 协方差
4. 相关系数
5. 矩

### 4.2 数学期望

#### 4.2.1 离散型随机变量的数学期望

设离散型随机变量 $X$ 的分布律为 $P\{X=a_i\} = p_i,i=1,2,\dots$，若级数 $\displaystyle \sum_{i=1}^{+\infty}a_i p_i$ 绝对收敛（即 $\displaystyle \sum_{i=1}^{+\infty} |a_i| p_i）< +\infty$），则称 $X$ 的数学期望存在，记为 $EX$，且定义数学期望为

$$ EX = \sum_{i=1}^{+\infty} a_i P\{X=a_i\} = p_i =\sum_{i=1}^{+\infty}a_i p_i $$

它表征的是随机变量 $X$ 取值的平均值，可简称为“均值”或“期望”。

#### 4.2.2 连续型随机变量的数学期望

设 $f(x)$ 为连续型随机变量 $X$ 的密度函数，如果积分 $\displaystyle \int_{-\infty}^{+\infty} x f(x) \mathrm d x$ 绝对收敛（即 $\displaystyle \int_{-\infty}^{+\infty} |x| f(x) \mathrm d x < + \infty$），则称 $X$ 的数学期望存在，记为 $EX$，且定义

$$EX=\int_{-\infty}^{+\infty} x f(x) \mathrm d x$$

#### 4.2.3 随机变量函数的数学期望

若随机变量 $X$ 的分布用分布律 $P\{X=a_i\}=p_i,i=1,2,\dots$ 或密度函数 $f(x)$ 表示，则 $X$ 的某一函数 $g(X)$ 的数学期望为

$$E[g(X)] = \begin{cases} \displaystyle \sum_{i=1}^{+\infty}g(a_i)P\{X=a_i\}, & X 为离散型 \\ \displaystyle \int_{-\infty}^{+\infty}g(x)f(x)\mathrm d x, & X 为连续型 \end{cases}$$

若随机变量 $(X,Y)$ 的分布用联合分布律 $P\{X=a_i,Y=b_j\},\quad i,j=1,2,\dots$ 或联合密度函数 $f(x,y)$ 表示，则 $(X,Y)$ 的某一函数 $g(X,Y)$ 的数学期望为

$$E[g(X,Y)] = \begin{cases} \displaystyle \sum_{i=1}^{+\infty} \displaystyle \sum_{j=1}^{+\infty} g(a_i,b_j)P\{X=a_i,Y=b_j\}, & (X,Y) 为离散型 \\ \displaystyle \int_{-\infty}^{+\infty} \displaystyle \int_{-\infty}^{+\infty} g(x,y)f(x,y) \mathrm d x \mathrm d y, & (X,Y) 为连续型 \end{cases}$$

#### 4.2.4 数学期望的性质

1. 设 $c$ 为常数，则 $Ec=c$；
2. 设 $X$ 为随机变量，$a,b$ 为任意实数，则 $E(aX+b) = aEX+b$；
3. 设 $X,Y$ 是任意两个随机变量，则 $E(aX+bY) = aEX+bEY$；
4. 如果 $X,Y$ 相互独立，则 $E(XY) = EX \cdot EY$

### 4.3 方差

是一个反映随机变量取值偏离平均值的程度的数字特征。

#### 4.3.1 方差的定义

设 $X$ 是随机变量，如果 $E(X-EX)^2 < + \infty$，则称 $E(X-EX)^2$ 为 $X$ 的方差，记为 $DX$，即

$$DX = \begin{cases} \displaystyle \sum_{i=1}^{+\infty} (a_i-EX)^2 P\{X=a_i\}, & X为离散型 \\ \displaystyle \int_{-\infty}^{+\infty}(x-EX)^2f(x)\mathrm dx, & X 为连续型 \end{cases}$$

并称 $\sqrt{DX}$ 为 $X$ 的标准差或均方差，记作 $\sigma$。

#### 4.3.2 方差的性质

1. 设 $c$ 为常数，则 $Dc=0$；
2. 设 $a,b$ 为任意实数，则 $D(aX+b) = a^2 DX$；
3. $D(X \pm Y) = DX+DY \pm 2E[(X - EX)(Y-EY)]$；
4. 若 $X,Y$ 互相独立，则 $D(X \pm Y)=DX+DY$。
5. 对于任意实数 $x$，有 $DX=E(X-EX)^2 \leqslant E(X-x)^2$，且等号成立的充要条件是 $x=EX$；
6. （**切比雪夫不等式**)设 $X$ 的方差存在，则对任意正数 $\varepsilon > 0$，有 $$P\{|X-EX| \geqslant\varepsilon \} \leqslant \frac{DX}{\epsilon^2}$$ 或 $$P\{|X-EX| < \varepsilon \} \geqslant 1 - \frac{DX}{\varepsilon^2}$$
7. $DX=0$ 的充要条件是 $X$ 以概率 1 取常数 $c$，即 $P\{X=c\}=1$

如果随机变量 $X$ 的方差 $DX$ 存在，且 $DX>0$ ,令

$$X^* = \frac{X-EX} {\sqrt{DX} }$$

称 $X^*$ 为 $X$ 的**标准化随机变量**。显然，$EX^* = 0, DX^* = 1$，这也就是称 $X^*$ 为标准化随机变量的原因。标准化的目的主要是消除量纲、期望以及方差的不同对数据比较所造成的影响。

### 4.4 协方差与相关系数

描述随机变量之间相关关系的数字特征：协方差与相关系数。

#### 4.4.1 协方差与相关系数的概念

在方差性质这一节中，通过性质 3 和性质 4 的描述可以知道，当 $X$ 与 $Y$ 相互独立时，有 $E[(X - EX)(Y-EY)] = 0$，也就是说当上式不为 0 的时候 $X$ 与 $Y$ 必然不独立。

设 $(X,Y)$ 为二维随机变量，如果 $E[(X - EX)(Y-EY)]$ 存在，则称

$$\mathrm {cov} (X,Y) = E[(X - EX)(Y-EY)] = E(XY) - EX \cdot EY$$

为 $X$ 与 $Y$ 的协方差。

如果对二维随机变量 $(X,Y)$ 分别进行标准化，即令 $X^* = \dfrac{X-EX} {\sqrt{DX} }, Y^* = \dfrac{Y-EY} {\sqrt{DY} },DX>0,DY>0$，则

$$\rho(X,Y) = \mathrm {cov} (X^*,Y^*) = E(X^* Y^*) = \dfrac {E[(X - EX)(Y-EY)]} {\sqrt{DX} \sqrt{DY} } = \dfrac {\mathrm {cov} (X,Y)} {\sqrt{DX} \sqrt{DY} }$$

称 $\rho(X,Y)$ 为 $X$ 与 $Y$ 的相关系数，简单记为 $\rho_{XY}$。

协方差是一个有量纲的数，而相关系数是一个无量纲的数。相关系数能很好地反映随机变量之间的关系，不受量纲影响。

#### 4.4.2 协方差与相关系数的性质

协方差有如下性质

1. 设 $c$ 为常数，则 $\mathrm {cov}(c,X)=0$；
2. $\mathrm{cov}(X,X) = DX$；
3. $\mathrm{cov}(X,Y) = \mathrm{cov}(Y,X)$；
4. 设 $a,b$ 为常数，则 $\mathrm{cov}(aX,bX) = ab \mathrm{cov}(X,Y)$；
5. $\mathrm{cov}(X+Y,Z) = \mathrm{cov}(X,Z) + \mathrm{cov}(Y,X)$；
7. $D(X \pm Y) = DX + DY \pm 2 \mathrm{cov}(X,Y)$。

由协方差的性质，显然以下三个性质等价：

1. $\mathrm{cov}(X,Y) = 0$；
2. $E(XY) = EX \cdot EY$；
3. $D(X \pm Y) = DX + DY$。

相关系数有如下性质

1. $|\rho (X,Y)| \leqslant 1$；
2. $\rho (X,Y) = \pm 1$ 的充要条件为 $X$ 与 $Y$ 以概率 1 线性相关，即 $$P\left\{ \dfrac {X-EX} {\sqrt{DX} } = \pm \dfrac{Y-EY} {\sqrt{DY} } \right\} = 1$$

若 $\rho(X,Y)=0$，则称 $X$ 与 $Y$ 不（线性）相关；若 $\rho(X,Y) \neq 0$，则称 $X$ 与 $Y$ （线性）相关。

相关系数刻画了随机变量 $X$ 与 $Y$ 之间的线性相依程度。如果 $\rho(X,Y) = +1$，称 $X$ 与 $Y$ 正线性相关；如果 $\rho(X,Y) = -1$，称 $X$ 与 $Y$ 负线性相关。$\rho(X,Y)$ 越接近于 $+1$，表示 $X$ 越接近于 $Y$ 的线性表达，即表达式 $Y=aX+b,a>0$ 越是处处成立；$\rho(X,Y)$ 越接近于 $-1$，表示 $X$ 越接近于 $Y$ 的系数为负的线性表达，即表达式 $Y=-aX+b,a>0$ 越是处处成立；$\rho(X,Y)$ 越接近于 0，表示 $X$ 与 $Y$ 的线性关系越弱。

**$X$ 与 $Y$ 独立，则 $X$ 与 $Y$ 不相关，但是反之则不然，因为 $X$ 与 $Y$ 不线性相关，还可能存在非线性关系，所以反之却不一定是成立的。**

**对于二维正态随机变量 $(X,Y) \sim N(\mu_1,\sigma_1^2;\mu_2,\sigma_2^2;\rho$，可以证明其参数 $\rho = \rho(X,Y)$，对于二维正太分布来说，$X$ 与 $Y$ 独立的充要条件是 $X$ 与 $Y$ 不相关，即 $\rho(X,Y)=0$。**

#### 4.4.3 协方差矩阵与相关系数矩阵



### 4.5 矩

#### 4.5.1 原点矩与中心矩

**常见分布的随机变量的重要数字特征**

## 5.极限定理

### 5.1 极限定理的概念和意义

### 5.2 大数定律

### 5.3 中心极限定理

## 6.数理统计的基本概念

### 6.1 数理统计的意义

### 6.2 总体与样本

### 6.3 统计量

### 6.4 经验分布函数与直方图

### 6.5 抽样分布

## 7.参数估计

### 7.1 参数估计的基本概念

### 7.2 点估计

### 7.3 估计优劣的评价标准

### 7.4 区间估计

## 8.假设检验

### 8.1 假设检验的基本原理与步骤

### 8.2 参数假设检验

### 8.3 非参数假设检验

## 9.回归分析

### 9.1 回归分析的基本概念

### 9.2 一元线性回归

### 9.3 一元非线性回归

### 9.4 多元线性回归简介