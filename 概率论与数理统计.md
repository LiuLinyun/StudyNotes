# 概率论与数理统计

## 1.随机事件及其概率

### 1.2.随机事件

#### 1.2.1 随机事件的定义

定义：

* 试验可以在相同条件下重复进行；
* 每次试验可能结果不止一个，并且试验前可以确定所有可能出现的结果；
* 每次试验之前不能准确预言出哪一个结果会出现。

具有以上三个特征的试验称为随机试验。

#### 1.2.2 样本空间

将随机试验 $E$ 中可能出现的基本结果称为样本点，一般用小写字母 $w,e$ 等表示，由所有样本点组成的集合称为 $E$ 的样本空间，记为 $\varOmega$。

#### 1.2.3 样本空间的集合表示

我们用样本空间 $\varOmega$ 中的子集代表随机事件 $A$，也可以记为基本样本点的一个集合，如 $A=\{w_1,w_2,w_3 \}$。

#### 1.2.4 事件之间的关系及运算

1. **子事件**：如果事件 $A$ 的样本点也属于事件 $B$，则称 $A$ 为 $B$ 的子事件。记为 $A \subset B$。如果事件 $A$ 与 $B$ 互为子事件，则称事件 $A$ 与 $B$ 相等，记为 $A = B$。
2. **和事件**:
3. **积事件**
4. **互斥事件与对立事件**
5. **差事件**
6. **完备事件组**

#### 1.2.5 事件的运算法则

### 1.3 事件的概率

#### 1.3.3 古典概率

设事件 $E$ 的样本空间 $\varOmega$ 由 $n$ 个样本点组成，毎个样本点等可能发生，事件 $A$ 由 $r$ 个样本点组成，则定义事件 $A$ 的概率为 $\dfrac r n$，记为 $P(A)$，即

$$P(A) = \dfrac {\text{A中样本点数} } {\varOmega \text{中样本点数} }   = \dfrac r n$$

#### 1.3.4 几何概率

设随机事件 $E$ 的样本空间 $\varOmega$ 为可测（有界）的区域，事件 $A$ 可以用 $\varOmega$ 中的子区域 $A$ 表示，即样本点落在区域 $A$ 中，表明事件 $A$ 发生。如果事件 $A$ 出现的可能性与该区域的几何测度有关，而与该区域的位置和形状无关，则称随机事件 $E$ 为几何概率，并定义 $A$ 的几何概率为

$$P(A) = \dfrac {A 的几何测度 } {\varOmega 的几何测度}$$

### 1.4 条件概率

#### 1.4.1 条件概率的定义

条件概率是指在某事件 $A$ 已经发生的情况下，事件 $B$ 发生的概率，记为 $P(B|A)$。设 $A,B$ 是样本空间 $\varOmega$ 中的两个随机事件，如果 $P(A)>0$，则称 $\dfrac {P(AB)} {P(A)}$ 为事件 $A$ 发生的条件下事件 $B$ 发生的 **条件概率**，记为 $P(B|A)$，即

$$P(B|A) = \dfrac {P(AB)} {P(A)}$$

#### 1.4.2 乘法公式

设两个随机事件 $A,B$，如果 $P(A)>0,P(B)>0$，则

$$P(AB) = P(A)P(B|A) = P(B)P(A|B)$$

被称为乘法公式。

意思是：$A,B$ 两个事件乘积的概率，也就是同时发生的概率，等于先求事件 $A$ 发生的概率，再乘以事件 $B$ 在事件 $A$ 已发生条件下的概率。

#### 1.4.3 全概率公式

设事件 $A_1,A_2,\dots,A_n$ 是两两互斥的， $P(A_i) > 0,i=1,2,\dots,n$，事件 $B$ 满足关系 $B \subset \displaystyle \bigcup_{i=1}^n A_i$，则事件 $B$ 的概率计算有如下公式：

$$P(B) = \sum_{i=1}^n P(A_i)P(B|A_i)$$

上式被称为全概率公式。

意思是：欲求一个复杂事件 $B$ 的概率，可以用一组完备事件 $A_1,A_2,\dots,A_n$ 对 $B$ 进行剖分，先求 $B$ 在毎个 $A_i$ 条件下的概率 $P(B|A_i)$，再对条件概率以 $P(A_i)$ 为权值加权求和。

#### 1.4.4 贝叶斯公式

设事件 $A_1,A_2,\dots,A_n$ 是两两互斥的， $P(A_i) > 0,i=1,2,\dots,n$，事件 $B$ 满足关系 $B \subset \displaystyle \bigcup_{i=1}^n A_i$，且 $P(B)>0$，则在事件 $B$ 发生的条件下，各个事件 $A_k$ 发生的概率为

$$P(A_k|B) = \dfrac {P(A_kB)} {P(B)} = \dfrac {P(A_k)P(B|A_k)} {\displaystyle \sum_{i=1}^n P(A_i)P(B|A_i)}, \quad k=1,2,\dots,n$$

贝叶斯公式描述了一种由“结果”到“原因”的关系，反映出了当前事件发生下，引起该事件发生的原因的可能性。

### 1.5 事件的独立性

#### 1.5.1 两个事件的独立性

设 $A,B$ 为两个随机事件，如果

$$P(AB) = P(A)P(B)$$

则称事件 $A$ 与 $B$ 相互独立。

**Tip**：两事件 $A,B$ 的独立性与两事件 $A,B$ 的互斥是两个不同的概念，不要混淆。如 $A \subset \varOmega$，事件 $A$ 与 $\varOmega$ 是相互独立的，但是并不是互斥的。

#### 1.5.3 独立重复试验，二项概率公式

随机试验的独立性：设有两个随机试验 $E_1,E_2$，假如试验 $E_1$ 的任意一个结果（事件）与试验 $E_2$ 的任意一个结果（事件）都是相互独立的，则称这两个试验是相互独立的。

$n$ 重独立试验：如果有 $n$ 个相同的且相互独立的试验 $E_1,E_2,\dots,E_n$，则称这 $n$ 次试验为 $n$ 次独立重复试验或 $n$ 重独立试验。

伯努利试验：在试验 $E$ 中，如果试验的可能结果只有两个，或事件 $A$ 出现，或事件 $\overline A$ 出现，则称试验 $E$ 为伯努利试验，一般记事件 $A$ 出现的概率为 $p$，事件 $\overline A$ 出现的概率为 $1-p$。

二项概率公式：在 $n$ 重伯努利试验中，事件 $A$ 发生 $k$ 次（$0 \leqslant k \leqslant n$）的概率记为 $P_n(k)$，则

$$P_n(k) = \mathrm C_n^k p^k(1-p)^{n-k}$$

## 2.一维随机变量及其分布

### 2.1 随机变量及其分布函数

#### 2.1.1 随机变量

有些随机试验的可能结果都与数量有关，我们可以将随机试验的可能结果用不同的数值表示。如抛硬币试验中，用数“1”表示“正面出现”，数“2”表示“反面出现”，这样就可以把这个随机试验的结果是“1”或者“0”，若记 $w_1 = \{反面出现\},w_2=\{正面出现\}$，则这个试验的样本空间为 $\varOmega = \{ w_1,w_2 \}$，那么上述试验的结果的数值变化可以用下列单实值函数来描述：

$$X(w) = \begin{cases} 0, w=w_1 \\ 1, w=w_2 \end{cases}$$

显然，单实值函数 $X$ 是一个取值具有随机性的变量，称 $X$ 为随机变量。更加一般性的描述如下：

设 $\varOmega$ 为随机试验 $E$ 上的一个样本空间，$X$ 为 $\varOmega$ 上的一个单实值函数，若满足对任意的 $x \in \mathrm R$，有 $\{x \leqslant x\} = \{w|X(w) \leqslant x, w \in \varOmega \} \in \mathscr F$，其中 $\mathscr F$ 是事件域。则称 $X$ 为概率空间 $(\varOmega, \mathscr F,P)$ 上的随机变量。

#### 2.1.2 分布函数的定义

设 $X$ 为一个随机变量，对任意实数 $x$，$\{X \leqslant x\}$ 都是事件，我们可以求出它的概率 $ P\{X \leqslant x\}$，这个概率显然是 $x$ 的函数，它的值随 $x$ 的变化而变化。记

$$ F(x) = P\{X \leqslant x\}, \quad x \in \mathbf R $$

为 $X$ 的分布函数。

分布函数完整地给出了随机变量的统计规律性。

### 2.2 离散型随机变量及其分布

#### 2.2.1离散型随机变量及其分布律

如果随机变量 $X$ 取有有限多个或者可列多个不同的值，则称 $X$ 为离散型随机变量。

设 $X$ 为一个离散型随机变量，它的所有可能取值为 $a_1,a_2,a_3,\dots$， 则称概率 $p_i = P\{X=a_i\}，i=1,2,3,\dots$ 为 $X$ 的分布律或者概率分布。

$X$ 的分布函数 $F(x)$ 与 $X$ 的分布律 $p_i(i=1,2,\dots)$ 有如下关系

$$\begin{aligned} F(x) = \sum_{a_i \leqslant x} P\{X=a_i\}, \quad x \in \mathbf R \\
P\{X=a_i\} = F(a_i) - F(a_i - 0)
\end{aligned}$$

#### 2.2.2 常见离散型随机变量的分布律

1. 退化分布
2. 两点分布
3. 二项分布
4. 泊松分布
5. 几何分布
6. 负二项分布
7. 超几何分布

### 2.3 连续型随机变量及其分布

#### 2.3.1 连续型随机变量及其密度函数

设 $F(x)$ 为随机变量 $X$ 的分布函数，如果 $F(x)$ 可表示为非负函数 $f(x)$ 的积分，

$$ F(x) = \int_{-\infty}^x f(t)\mathrm dt, \quad x\in \mathbf R$$

则称 $x$ 为连续型随机变量。称 $f(x)$ 为 $X$ 的密度函数，简称为密度。称 $F(x)$ 为连续型分布函数。

注意：因为连续型随机变量 $X$ 的分布函数 $F(x)$ 关于 $x$ 是处处连续的，所以对于任意实数 $x$，有 $P\{X=x\} = F(x) - F(x-0) = 0$。由此可见，**概率为 0 的事件不一定是不可能事件，概率为 1 的事件也不一定是必然事件**。

#### 2.3.2 常见的连续型随机变量的密度函数

1. 均匀分布
2. 指数分布
3. 正态分布

### 2.4 随机变量函数的分布

#### 2.4.1 离散型随机变量函数的分布

离散型随机变量 $X$ 的函数 $g(X)$ 显然仍然是离散型随机变量，首先根据 $X$ 的所有可能取值求出 $g(X)$ 的所有可能取值，然后通过 $X$ 的分布律用列表法或分析法导出 $g(X)$ 的分布律。

#### 2.4.2 连续型随机变量函数的分布

如果连续型随机变量的函数仍然为连续型随机变量，我们先使用分布函数法先求出 $Y=g(X)$ 的分布 $F_Y(y)$，再对 $F_Y(y)$ 求导得到密度函数 $f_Y(y)$。

## 3.多维随机变量及其分布

### 3.1 二维随机变量及其分布函数

#### 3.1.1 二维随机变量及其分布函数

设 $\varOmega$ 是随机试验 $E$ 的样本空间，$X,Y$ 是定义在 $\varOmega$ 上的两个随机变量，则由 $X$ 和 $Y$ 构成的二维向量 $(X,Y)$ 称为 $\varOmega$ 上的二维随机变量或随机向量。

设 $(X,Y)$ 是二维随机变量，$x,y$ 是任意两个实数，则

$$ \{ X \leqslant x, Y \leqslant y\} = \{ w|X(w) \leqslant x 且 Y(w) \leqslant y, w \in \varOmega \}$$

是随机事件，且有

$$\{ X \leqslant x, Y \leqslant y\} = \{ X \leqslant x\} \cap \{ Y \leqslant y\} $$

设 $(X,Y)$ 为二维随机变量，对于任意实数 $x,y$ 记

$$F(x,y) = P\{X\leqslant x,Y\leqslant y\}$$

称 $F(x,y)$ 为二维随机变量 $(X,Y)$ 的联合分布函数，简称分布函数。

#### 3.1.2 二维离散型随机变量及其分布律

如果二维随机变量 $(X,Y)$ 的所有可能取值是有限个数对或可数多个数对，则称 $(X,Y)$ 是二维离散型随机变量。

设二维离散型随机变量 $(X,Y)$ 所有可能取值为 $\{ (a_i,b_j),\quad i,j = 1,2,\dots\}$ 且

$$P\{X=a_i,Y=b_j \} = p_{ij}, \quad i,j=1,2,\dots $$

则称 $p_{ij}$ 为二维离散型随机变量 $(X,Y)$ 的联合分布律或概率分布，简称为 $(X,Y)$ 的分布律。

二维离散型随机变量的联合分布函数和分布律有如下关系：

$$ \begin{aligned} F(x,y) & = \sum_{a_i \leqslant x, b_j \leqslant y} P\{X=a_i,Y=b_j\} \\
P\{X=a_i,Y=b_j\} & = F(a_i,b_j) - F(a_i,b_j-0)-F(a_i-0,b_j)+F(a_i-0,b_j-0)\end{aligned}$$

#### 3.1.3 二维连续型随机变量及其密度函数

设二维随机变量 $(X,Y)$ 的分布函数为 $F(x,y)$，如果存在非负二元可积函数 $f(x,y)$，使得对任意的实数 $x,y$，有

$$F(x,y) = \int_{-\infty}^x \int_{-\infty}^y f(u,v) \mathrm d u \mathrm d v$$

则称 $(X,Y)$ 是二维连续型随机变量，称函数 $f(x,y)$ 为 $(X,Y)$ 的联合密度函数，简称为密度函数。

### 3.2 边缘分布与随机变量的独立性

#### 3.2.1 边缘分布函数

边缘分布相对于联合分布而言，是指 $n(n\geqslant 2)$ 维随机变量的部分随机变量的分布，如二维随机变量 $(X,Y)$，边缘分布就是 $X$ 和 $Y$ 各自的概率分布。

$$\begin{aligned} F_X(x) = P(X \leqslant x) = P\{X\leqslant x,Y<+\infty\} = F(x,+\infty) \\
F_Y(y) = P(Y \leqslant y) = P\{X<+\infty,Y\leqslant y\} = F(+\infty,y)\end{aligned}$$

#### 3.2.2 边缘分布律

#### 3.2.3 边缘密度函数

设二维连续型随机变量 $(X,Y)$ 具有联合密度函数 $f(x,y)$，因为

$$\begin{aligned} F_X(x) = F(x, + \infty) = \int_{-\infty}^x \mathrm d x \int_{-\infty}^{+\infty} f(x,y) \mathrm d y = \int_{-\infty}^x f_X(x) \mathrm d x \\
F_Y(y) = F(+ \infty,y) = \int_{-\infty}^y \mathrm d y \int_{-\infty}^{+\infty} f(x,y) \mathrm d x = \int_{-\infty}^y f_Y(y) \mathrm d y\end{aligned}$$

其中

$$\begin{aligned} f_X(x) = \int_{-\infty}^{+\infty} f(x,y) \mathrm d y, \quad x \in \mathbf R \\
f_Y(y) = \int_{-\infty}^{+\infty} f(x,y) \mathrm d x, \quad y \in \mathbf R \end{aligned}$$

称 $f_X(x),f_Y(y)$ 分别为 $X$ 和 $Y$ 的边缘密度函数，即为 $(X,Y)$ 的边缘密度函数。

#### 3.2.4 两个随机变量间的独立性

设 $F(x,y)$ 及 $F_X(x), F_Y(y)$ 分别是二维随机变量 $(X,Y)$ 的联合分布函数及边缘分布函数，如果对任意实数 $x,y$ 有

$$P\{ X \leqslant x, Y \leqslant y\} = P\{ X \leqslant x\} \cdot P\{ Y \leqslant y\}$$

即

$$F(x,y) = F_X(x) \cdot  F_Y(y)$$

成立，则称随机变量 $X$ 和 $Y$ 相互独立。

当 $(X,Y)$ 是离散型随机变量时，$X$ 和 $Y$ 相互独立的条件等价于对所有 $(X,Y)$ 的可能取值 $(a_i,b_j)$，均有

$$P\{X=a_i,Y=b_j\} = P\{X=a_i\} \cdot P\{Y=b_j\}$$

当 $(X,Y)$ 是连续型随机变量时，$X$ 和 $Y$ 相互独立的条件等价于在联合密度函数的任意连续点 $(x,y)$，均有

$$f(x,y) = f_X(x) \cdot f_Y(y)$$

### 3.4 二维随机变量函数的分布

#### 3.4.1 二维离散型随机变量函数的分布

对于二维离散型随机变量 $(X,Y)$，当 $g(X,Y)$ 是二元连续函数时，其函数值 $Z=g(X,Y)$ 是一维离散型随机变量。当 $(X,Y)$ 的联合分布律已知时，求其函数 $Z=g(X,Y)$ 的分布律，主要方法有列表计算法和归纳分析法。

#### 3.4.2 二维连续型随机变量函数的分布

对于二维连续型随机变量 $(X,Y)$，当 $g(X,Y)$ 是二元连续函数时，其函数 $Z=g(X,Y)$ 是一维连续型随机变量。当 $(X,Y)$ 的联合密度函数已知时，求其函数 $Z=g(X,Y)$ 的密度函数。具体做法是：先求分布函数 $F_Z(z) = P\{g(X,Y) \leqslant z\}$，通过 $F_Z'(z)$ 再求密度函数 $f_Z(z)$。

## 4.随机变量的数字特征

### 4.1 常见的数字特征

1. 数学期望（均值）
2. 方差
3. 协方差
4. 相关系数
5. 矩

### 4.2 数学期望

#### 4.2.1 离散型随机变量的数学期望

设离散型随机变量 $X$ 的分布律为 $P\{X=a_i\} = p_i,i=1,2,\dots$，若级数 $\displaystyle \sum_{i=1}^{+\infty}a_i p_i$ 绝对收敛（即 $\displaystyle \sum_{i=1}^{+\infty} |a_i| p_i）< +\infty$），则称 $X$ 的数学期望存在，记为 $EX$，且定义数学期望为

$$ EX = \sum_{i=1}^{+\infty} a_i P\{X=a_i\} = p_i =\sum_{i=1}^{+\infty}a_i p_i $$

它表征的是随机变量 $X$ 取值的平均值，可简称为“均值”或“期望”。

#### 4.2.2 连续型随机变量的数学期望

设 $f(x)$ 为连续型随机变量 $X$ 的密度函数，如果积分 $\displaystyle \int_{-\infty}^{+\infty} x f(x) \mathrm d x$ 绝对收敛（即 $\displaystyle \int_{-\infty}^{+\infty} |x| f(x) \mathrm d x < + \infty$），则称 $X$ 的数学期望存在，记为 $EX$，且定义

$$EX=\int_{-\infty}^{+\infty} x f(x) \mathrm d x$$

#### 4.2.3 随机变量函数的数学期望

若随机变量 $X$ 的分布用分布律 $P\{X=a_i\}=p_i,i=1,2,\dots$ 或密度函数 $f(x)$ 表示，则 $X$ 的某一函数 $g(X)$ 的数学期望为

$$E[g(X)] = \begin{cases} \displaystyle \sum_{i=1}^{+\infty}g(a_i)P\{X=a_i\}, & X 为离散型 \\ \displaystyle \int_{-\infty}^{+\infty}g(x)f(x)\mathrm d x, & X 为连续型 \end{cases}$$

若随机变量 $(X,Y)$ 的分布用联合分布律 $P\{X=a_i,Y=b_j\},\quad i,j=1,2,\dots$ 或联合密度函数 $f(x,y)$ 表示，则 $(X,Y)$ 的某一函数 $g(X,Y)$ 的数学期望为

$$E[g(X,Y)] = \begin{cases} \displaystyle \sum_{i=1}^{+\infty} \displaystyle \sum_{j=1}^{+\infty} g(a_i,b_j)P\{X=a_i,Y=b_j\}, & (X,Y) 为离散型 \\ \displaystyle \int_{-\infty}^{+\infty} \displaystyle \int_{-\infty}^{+\infty} g(x,y)f(x,y) \mathrm d x \mathrm d y, & (X,Y) 为连续型 \end{cases}$$

#### 4.2.4 数学期望的性质

1. 设 $c$ 为常数，则 $Ec=c$；
2. 设 $X$ 为随机变量，$a,b$ 为任意实数，则 $E(aX+b) = aEX+b$；
3. 设 $X,Y$ 是任意两个随机变量，则 $E(aX+bY) = aEX+bEY$；
4. 如果 $X,Y$ 相互独立，则 $E(XY) = EX \cdot EY$

### 4.3 方差

是一个反映随机变量取值偏离平均值的程度的数字特征。

#### 4.3.1 方差的定义

设 $X$ 是随机变量，如果 $E(X-EX)^2 < + \infty$，则称 $E(X-EX)^2$ 为 $X$ 的方差，记为 $DX$，即

$$DX = \begin{cases} \displaystyle \sum_{i=1}^{+\infty} (a_i-EX)^2 P\{X=a_i\}, & X为离散型 \\ \displaystyle \int_{-\infty}^{+\infty}(x-EX)^2f(x)\mathrm dx, & X 为连续型 \end{cases}$$

并称 $\sqrt{DX}$ 为 $X$ 的标准差或均方差，记作 $\sigma$。

#### 4.3.2 方差的性质

1. 设 $c$ 为常数，则 $Dc=0$；
2. 设 $a,b$ 为任意实数，则 $D(aX+b) = a^2 DX$；
3. $D(X \pm Y) = DX+DY \pm 2E[(X - EX)(Y-EY)]$；
4. 若 $X,Y$ 互相独立，则 $D(X \pm Y)=DX+DY$。
5. 对于任意实数 $x$，有 $DX=E(X-EX)^2 \leqslant E(X-x)^2$，且等号成立的充要条件是 $x=EX$；
6. （**切比雪夫不等式**)设 $X$ 的方差存在，则对任意正数 $\varepsilon > 0$，有 $$P\{|X-EX| \geqslant\varepsilon \} \leqslant \frac{DX}{\epsilon^2}$$ 或 $$P\{|X-EX| < \varepsilon \} \geqslant 1 - \frac{DX}{\varepsilon^2}$$
7. $DX=0$ 的充要条件是 $X$ 以概率 1 取常数 $c$，即 $P\{X=c\}=1$

如果随机变量 $X$ 的方差 $DX$ 存在，且 $DX>0$ ,令

$$X^* = \frac{X-EX} {\sqrt{DX} }$$

称 $X^*$ 为 $X$ 的**标准化随机变量**。显然，$EX^* = 0, DX^* = 1$，这也就是称 $X^*$ 为标准化随机变量的原因。标准化的目的主要是消除量纲、期望以及方差的不同对数据比较所造成的影响。

### 4.4 协方差与相关系数

描述随机变量之间相关关系的数字特征：协方差与相关系数。

#### 4.4.1 协方差与相关系数的概念

在方差性质这一节中，通过性质 3 和性质 4 的描述可以知道，当 $X$ 与 $Y$ 相互独立时，有 $E[(X - EX)(Y-EY)] = 0$，也就是说当上式不为 0 的时候 $X$ 与 $Y$ 必然不独立。

设 $(X,Y)$ 为二维随机变量，如果 $E[(X - EX)(Y-EY)]$ 存在，则称

$$\mathrm {cov} (X,Y) = E[(X - EX)(Y-EY)] = E(XY) - EX \cdot EY$$

为 $X$ 与 $Y$ 的协方差。

如果对二维随机变量 $(X,Y)$ 分别进行标准化，即令 $X^* = \dfrac{X-EX} {\sqrt{DX} }, Y^* = \dfrac{Y-EY} {\sqrt{DY} },DX>0,DY>0$，则

$$\rho(X,Y) = \mathrm {cov} (X^*,Y^*) = E(X^* Y^*) = \dfrac {E[(X - EX)(Y-EY)]} {\sqrt{DX} \sqrt{DY} } = \dfrac {\mathrm {cov} (X,Y)} {\sqrt{DX} \sqrt{DY} }$$

称 $\rho(X,Y)$ 为 $X$ 与 $Y$ 的相关系数，简单记为 $\rho_{XY}$。

协方差是一个有量纲的数，而相关系数是一个无量纲的数。相关系数能很好地反映随机变量之间的关系，不受量纲影响。

#### 4.4.2 协方差与相关系数的性质

协方差有如下性质

1. 设 $c$ 为常数，则 $\mathrm {cov}(c,X)=0$；
2. $\mathrm{cov}(X,X) = DX$；
3. $\mathrm{cov}(X,Y) = \mathrm{cov}(Y,X)$；
4. 设 $a,b$ 为常数，则 $\mathrm{cov}(aX,bX) = ab \mathrm{cov}(X,Y)$；
5. $\mathrm{cov}(X+Y,Z) = \mathrm{cov}(X,Z) + \mathrm{cov}(Y,X)$；
7. $D(X \pm Y) = DX + DY \pm 2 \mathrm{cov}(X,Y)$。

由协方差的性质，显然以下三个性质等价：

1. $\mathrm{cov}(X,Y) = 0$；
2. $E(XY) = EX \cdot EY$；
3. $D(X \pm Y) = DX + DY$。

相关系数有如下性质

1. $|\rho (X,Y)| \leqslant 1$；
2. $\rho (X,Y) = \pm 1$ 的充要条件为 $X$ 与 $Y$ 以概率 1 线性相关，即 $$P\left\{ \dfrac {X-EX} {\sqrt{DX} } = \pm \dfrac{Y-EY} {\sqrt{DY} } \right\} = 1$$

若 $\rho(X,Y)=0$，则称 $X$ 与 $Y$ 不（线性）相关；若 $\rho(X,Y) \neq 0$，则称 $X$ 与 $Y$ （线性）相关。

相关系数刻画了随机变量 $X$ 与 $Y$ 之间的线性相依程度。如果 $\rho(X,Y) = +1$，称 $X$ 与 $Y$ 正线性相关；如果 $\rho(X,Y) = -1$，称 $X$ 与 $Y$ 负线性相关。$\rho(X,Y)$ 越接近于 $+1$，表示 $X$ 越接近于 $Y$ 的线性表达，即表达式 $Y=aX+b,a>0$ 越是处处成立；$\rho(X,Y)$ 越接近于 $-1$，表示 $X$ 越接近于 $Y$ 的系数为负的线性表达，即表达式 $Y=-aX+b,a>0$ 越是处处成立；$\rho(X,Y)$ 越接近于 0，表示 $X$ 与 $Y$ 的线性关系越弱。

**$X$ 与 $Y$ 独立，则 $X$ 与 $Y$ 不相关，但是反之则不然，因为 $X$ 与 $Y$ 不线性相关，还可能存在非线性关系，所以反之却不一定是成立的。**

**对于二维正态随机变量 $(X,Y) \sim N(\mu_1,\sigma_1^2;\mu_2,\sigma_2^2;\rho$，可以证明其参数 $\rho = \rho(X,Y)$，对于二维正太分布来说，$X$ 与 $Y$ 独立的充要条件是 $X$ 与 $Y$ 不相关，即 $\rho(X,Y)=0$。**

#### 4.4.3 协方差矩阵与相关系数矩阵

设随机变量 $\boldsymbol X = (X_1,X_2,\dots,X_n)^T$，若 $\sigma_{ij} = \mathrm{cov}(X_i,X_j),i,j=1,2,\dots,n$ 均存在，则称

$$\boldsymbol \varSigma = \begin{bmatrix}
\sigma_{11} & \sigma_{12} & \cdots & \sigma_{1n} \\
\sigma_{21} & \sigma_{22} & \cdots & \sigma_{2n} \\
\vdots      & \vdots      & \ddots & \vdots      \\
\sigma_{n1} & \sigma_{n2} & \cdots & \sigma_{nn} 
\end{bmatrix}$$

为随机变量 $\boldsymbol X = (X_1,X_2,\dots,X_n)^T$ 的协方差矩阵。显然**协方差矩阵 $\boldsymbol \varSigma$ 是个 $n$ 阶对称矩阵，主对角线元素 $\sigma_{ii} = DX_i,i=1,2,\dots,n$。还可以证明它是个 $n$ 阶对称非负定矩阵**。

设随机变量 $\boldsymbol X = (X_1,X_2,\dots,X_n)^T$ 有协方差矩阵 $\boldsymbol \varSigma$，则称

$$\boldsymbol \varSigma = \begin{bmatrix}
\rho_{11} & \rho_{12} & \cdots & \rho_{1n} \\
\rho_{21} & \rho_{22} & \cdots & \rho_{2n} \\
\vdots    & \vdots    & \ddots & \vdots    \\
\rho_{n1} & \rho_{n2} & \cdots & \rho_{nn} 
\end{bmatrix}$$

为随机变量 $\boldsymbol X = (X_1,X_2,\dots,X_n)^T$ 的相关系数矩阵，其中 $\rho_{ij} = \rho(X_i,X_j),i,j=1,2,\dots,n$。由定义可知，$\boldsymbol R$ 与 $\boldsymbol \varSigma$ 有如下关系

$$ \boldsymbol R = \boldsymbol D^{-1} \boldsymbol \varSigma \boldsymbol D^{-1}$$

其中 $\boldsymbol D = \mathrm{diag}(\displaystyle \sqrt{DX_1},\displaystyle \sqrt{DX_2},\cdots,\displaystyle \sqrt{DX_n})$。

### 4.5 矩

前面讨论了数学期望、方差、协方差等随机变量的数字特征。从计算公式来看，它们都是随机变量数学期望的计算，与物理学中静力矩和惯性矩计算公式相似，因此借用物理学中“矩”的名字，把它们统称为随机变量的矩。

#### 4.5.1 原点矩与中心矩

设 $X$ 为随机变量，如果对正整数 $k$，$E(X^k)$ 存在，则称 $E(X^k)$ 为 $X$ 的 $k$ 阶原点矩；如果 $E(X-EX)^k$ 存在，则称 $E(X-EX)^k$ 为 $X$ 的 $k$ 阶中心矩。

由定义可知，数学期望是一阶原点矩，方差是二阶中心矩。若按公式 $DX=EX^2 - (EX)^2$，方差是二阶原点矩与一阶原点矩平方之差。

**常见分布的随机变量的重要数字特征**



## 5.极限定理

### 5.1 极限定理的概念和意义

在相同条件下进行多次重复随机试验，将第 $n$ 次试验出现的结果记为 $X_n$，这时所得到的 $\{X_n,n=1,2,\dots\}$ 称为随机变量序列，也可记为 $\{X_n\}$。随机变量序列的极限反映了当 $n$ 充分大的时候序列的变化趋势。

设随机变量序列 $\{X_n,n=1,2,\dots\}$，对随机变量 $X$ 和任意实数 $\varepsilon > 0$，如果有

$$\lim_{n \rightarrow +\infty} P\{|X_n - X| < \varepsilon\} = 1$$

则称随机变量序列 $\{X_n\}$ **依概率收敛于**随机变量 $X$，简记为 $X_n \xrightarrow[n \rightarrow +\infty]{P} X$。

设随机变量序列 $\{X_n,n=1,2,\dots\}$ 和 $X$ 的分布函数分别为 $F_n(x),F(x)$。对任意的实数 $x$，如果有 

$$\lim_{n \rightarrow +\infty} F_n(x) = F(x)$$

则称随机变量序列 $\{X_n\}$ **依分布收敛于**随机变量 $X$，简记为 $X_n \xrightarrow[n \rightarrow +\infty]{L} X$。

基本的极限定理分为两类，一类称为**大数定律**，它反映的是序列 $\{X_n\}$ 的前有限项的算数平均的变化趋势，另一类称为**中心极限定理**，该定理表明，在一般条件下，正态分布是很重要的极限分布，这为我们广泛使用正态分布研究自然现象或者作为近似计算工具提供了有力的支持。

### 5.2 大数定律

大数定律由概率的统计定义“频率收敛于概率”引申而来。假设 $X_i$ 表示第 $i$ 个人的身高或第 $i$ 件产品的寿命等，$X_i,i=1,2,\dots$ 独立同分布，令 $EX_i = a$，则 $\displaystyle \frac 1 n \sum_{i=1}^n X_i$ 反映的是 $n$ 个人的平均身高或 $n$ 件产品的平均寿命等，当 $n$ 足够大时，它们趋于期望值 $a$，这就是大数定律的思想。

(**切比雪夫大数定律**)设相互独立的随机变量序列 $\{X_i\},EX_i,DX_i,i=1,2,\dots$ 都存在，并且存在常数 $C$，使得 $DX_i \leqslant C, i=1,2,\dots$，则对任意实数 $\varepsilon > 0$，有

$$\lim_{n \rightarrow +\infty} P\{|\overline X_n - E \overline X_n| < \varepsilon\} = 1$$

其中 $\overline X_n = \dfrac 1 n \displaystyle \sum_{i=1}^n X_i$。

特别地，当上述的随机变量序列 $\{X_i\}$ 独立同分布，且 $EX_i = \mu, DX_i = \sigma^2, i=1,2,\dots$ 存在，则这样条件下的切比雪夫大数定律也称为辛钦大数定律。

（**辛钦大数定律**）设 $\{X_i\}$ 为独立同分布的随机变量序列，$EX_i,DX_i, i=1,2,\dots$ 都存在，令 $EX_i = \mu,DX_i = \sigma^2, i=1,2,\dots$，则对任意的实数 $\varepsilon > 0$，有

$$\lim_{n \rightarrow +\infty} P\{|\overline X_n - \mu| < \varepsilon\} = 1$$

即 **$\overline X_n = \dfrac 1 n \displaystyle \sum_{i=1}^n X_i$ 依概率收敛于 $\mu$，记为 $\overline X_n \xrightarrow[n \rightarrow +\infty]{P} \mu$** 。

（**伯努利大数定律**）设 $\{X_i\}$ 为独立同分布的随机变量序列，且 $X_i \sim B(1,p),i=1,2,\dots$，记 $\mu_n = \displaystyle \sum_{i=1}^n X_i$，则对任意的实数 $\varepsilon > 0$，有

$$\lim_{n \rightarrow +\infty} P \left\{\left|\dfrac {\mu_n} {n} - p \right| < \varepsilon \right\} = 1$$

即 $\dfrac {\mu_n} {n} \xrightarrow[n \rightarrow +\infty]{P} p$。

伯努利大数定律显示，随着 $n$ 的增大，事件 $A$ 发生的频率 $\dfrac {\mu_n}{n}$ 与其概率 $p$ 的偏差会小于预先给定的任意正数 $\varepsilon > 0$ 的可能性越来越大。这在理论上印证了频率的稳定性，为用频率来估计概率提供了理论依据。

### 5.3 中心极限定理

中心极限定理研究的是独立随机变量序列 $\{X_n,n=1,2,\dots\}$ 的 $n$ 项之和 $\displaystyle \sum_{i=1}^n X_i$ 的极限分布。对于实际问题中需要求若干个独立同分布的随机变量之和 $\displaystyle \sum_{i=1}^n X_i$ 的分布，可以多次使用卷积公式计算，但是这样的计算很复杂，一个很自然的想法是利用熟悉的分布进行近似计算。事实上， **在一般情况下，$\displaystyle \sum_{i=1}^n X_i$ 的极限分布就是正态分布。**

**（独立同分布的中心极限定理）** 设 $\{X_n\}$ 为独立同分布的随机变量序列，$EX_i,DX_i, i=1,2,\dots$ 都存在，令 $EX_i = \mu,DX_i = \sigma^2, i=1,2,\dots$，则对任意的实数 $x$，有

$$\lim_{n \rightarrow +\infty} P \left\{\dfrac {\overline X_n - \mu} {\sigma / \sqrt{n} }  \leqslant \varepsilon \right\} = \varPhi(x)$$

其中 $\overline X_n = \dfrac 1 n \displaystyle \sum_{i=1}^n X_i$，$\varPhi(x)$ 为标准正态分布 $N(0,1)$ 的分布函数。

记 $\dfrac{\overline X_n - \mu}{\sigma / \sqrt n} \overset{近似}{\sim} N(0,1)$，或 $\displaystyle \sum_{i=1}^n X_i \overset{近似}{\sim} N(n\mu,n\sigma^2)$，称 $\overline X_n$ 依分布收敛于正态分布 $N(\mu, \dfrac {\sigma^2}{n})$。

该定理告诉我们，只有当 $n$ 充分大时，随机变量 $\dfrac{\overline X_n - \mu}{\sigma / \sqrt n}$ 才近似服从标准正态分布 $N(0,1)$，$\displaystyle \sum_{i=1}^n X_i$ 近似服从正态分布 $N(n\mu,n\sigma^2)$，当 $n$ 比较小时，这种近似不成立。

**（棣莫弗-拉普拉斯定理）** 设 $\{X_i\}$ 为独立同分布的随机变量序列，且 $X_i \sim B(1,p), i=1,2,\dots$，令 $Y_n = \displaystyle \sum_{i=1}^n X_i$，则对于任意的实数 $x$，有

$$\lim_{n \rightarrow +\infty} P\left\{ \dfrac{Y_n - np}{\sqrt{np(1-np)} } \leqslant x \right\} = \varPhi(x)$$

值得注意的是， $Y_n = \displaystyle \sum_{i=1}^n X_i$ 的精确分布是二项分布 $B(n,p)$，因此，该定理揭示了正态分布是二项分布的极限分布，常称为“二项分布的正态近似”。

## 6.数理统计的基本概念

### 6.1 数理统计的意义

之前我们学习了如何用随机变量及其概率分布去描述随机现象的统计规律，如何利用概率分布去分析随机变量的性质，计算事件的概率和随机变量的数字特征。但是，在实际问题中，概率分布往往是未知的，这使得许多问题的研究遇到困难，幸好，数理统计为我们提供了许多有效的解决方法。

数理统计也是研究随机现象及其统计规律的学科分支，但是它的研究方式与概率论不同，它是通过研究如何有效地收集、整理和分析随机变量的观测数据，对随机变量的性质和特征作出合理的推断或预测。

### 6.2 总体与样本

通常，把一个统计问题中的研究对象的全体称为 **总体**，组成总体的毎个成员称为 **个体**。总体实际上就是一个数据集合，在这个集合中，有的数据相同，有的不同，有的出现的可能性更大，有的出现的可能性更小，于是，我们用一个概率分布来描述总体，那个数量属性就是服从这个概率分布的随机变量，该随机变量的分布称为 **总体分布** 。在数理统计方法中，为了研究总体的某些性质或特征，需要从总体中随机抽取 $n$ 个个体进行观测，它们被称之为 **样本**，称 $n$ 为 **样本容量**。

举个栗子：考察某地校大学本科生去年的日常生活消费水平。用随机变量 $X$ 表示该校任意一个本科生去年的日常生活消费额，那么 $X$ 的全部取值就是这个学校去年的日常生活消费额组成的全体，即总体。总体的分布函数为 $F(x) = P\{X \leqslant x\},x \in \mathbf R$。要想了解该校所有本科生去年的日常生活消费整体情况，最直观的做法就是获取总体中的全部数据，也就是普查，但是普查费时耗力，作为日常管理和统计，我们通常是从总体中随机抽取 $n$ 个本科生，得到他们去年的生活消费额数据 $x_1,x_2,\dots,x_n$，然后利用这些数据的信息对总体的情况进行推断或估计。由于数据 $x_1,x_2,\dots,x_n$ 是随机抽取的结果，所以 $x_1,x_2,\dots,x_n$ 是 $n$ 维随机变量 $X_1,X_2,\dots,X_n$ 的一个观测值，我们称 $X_1,X_2,\dots,X_n$ 是来自总体 $X$ 的一个样本，$n$ 为样本容量，$x_1,x_2,\dots,x_n$ 为样本值， 它是 $X_1,X_2,\dots,X_n$ 的一次观测值。

在常规的统计推断方法中，一般要求样本 $X_1,X_2,\dots,X_n$ 是 **简单样本** ，具有以下两个特点：独立性（样本 $X_1,X_2,\dots,X_n$ 之间相互独立）和代表性（样本 $X_1,X_2,\dots,X_n$ 中的毎个随机变量与总体 $X$ 具有相同的概率分布）。

由所有样本值组成的集合 $\varOmega = \{(x_1,x_2,\dots,x_n) | x_i \in \mathbf R, i=1,2,\dots,n\}$ 称为 **样本空间** 。

### 6.3 统计量

样本来自总体，样本值中包含了总体各方面的信息。为了将存在于样本中的有关总体的信息挖掘出来用于对总体进行推断，就要对样本信息进行处理，最自然的想法就是构造样本的函数，针对不同的问题可以构造不同的样本的函数，我们称样本的函数为 **统计量** 。

设 $X_1,X_2,\dots,X_n$ 为来自总体 $X$ 的样本，$T(x_1,x_2,\dots,x_n)$ 是 $n$ 元连续函数，且不含任何未知参数，则称随机变量 $T(x_1,x_2,\dots,x_n)$ 为一个统计量。

#### 6.3.1 样本矩统计量

设 $X_1,X_2,\dots,X_n$ 为来自总体 $X$ 的样本，常见的样本矩统计量如下：

1. 样本均值 $\overline X = \dfrac 1 n \displaystyle \sum_{i=1}^n X_i$
2. 样本方差 $S^2 = \dfrac 1 {n-1} \displaystyle \sum_{i=1}^n (X_i - \overline X)^2$
3. 样本标准差 $S = \sqrt{S^2} = \sqrt{\dfrac 1 {n-1} \displaystyle \sum_{i=1}^n (X_i - \overline X)^2}$
4. 样本 $k$ 阶原点矩 $M_k = \dfrac 1 n \displaystyle \sum_{i=1}^n X_i^k, k=1,2,\dots$
5. 样本 $k$ 阶中心矩 $M_k^* = \dfrac 1 n \displaystyle \sum_{i=1}^n (X_i - \overline X)^k,k=1,2,\dots$

显然

1. $M_1 = \overline X$
2. $S^2 = \dfrac n {n-1} M_2^*$
3. $M_2^* = \dfrac 1 n \displaystyle \sum_{i=1}^n X_i^2 - \overline{X^2}$

样本均值 $\overline X$ 和样本方差 $S^2$ 有如下性质

1. $\displaystyle \sum_{i=1}^n (X_i - \overline X) = 0$
2. 若总体 $X$ 的均值 $EX$、方差 $DX$ 存在，则 $$E\overline X = EX, \quad D\overline X = \dfrac 1 n DX, \quad EM_2^* = \dfrac {n-1} n DX, \quad ES^2 = DX$$
3. 当 $n \rightarrow +\infty$ 时，$\overline X \xrightarrow {\quad P \quad} EX$
4. 对任意实数 $x$，有 $\displaystyle \sum_{i=1}^n (X_i - \overline X)^2 \leqslant \displaystyle \sum_{i=1}^n (X_i - x)^2$

#### 6.3.2 顺序统计量

除了样本矩统计量以外，另一类常见的统计量是 **顺序统计量** ，它计算量小、使用方便，在质量管理、可靠性等方面有广泛的应用。

设 $X_1,X_2,\dots,X_n$ 是来自总体 $X$ 的样本，对给定的一组样本观测值 $x_1,x_2,\dots,x_n$，按从小到大的顺序排列，用 $x_{(k)},k=1,2,\dots,n$ 表示大小位置在第 $k$ 位的数，这样就有 $x_{(1)} \leqslant x_{(2)} \leqslant \cdots \leqslant x_{(n)}$。当样本 $X_1,X_2,\dots,X_n$ 的观测值随机变化时，$x_{(k)},k=1,2,\dots,n$ 的取值也发生变化，且具有一定的随机性。这样，$x_{(k)},k=1,2,\dots,n$ 的全部取值就对应一个随机变量，记为 $X_{(k)},k=1,2,\dots,n$，它显然是一个统计量，我们称 $X_{(1)},X_{(2)},\dots,X_{(n)}$ 为样本 $X_1,X_2,\dots,X_n$ 的 **顺序统计量** 。特别地，称 $X_{(1)}$ 为 **最小顺序统计量** ，$X_{(n)}$ 为 **最大顺序统计量** 。令 $R=X_{(n)} - X_{(1)}$，称其为 **样本极差** ；$\widetilde X = \begin{cases} X_{((n+1)/2)},& n为奇数 \\ \dfrac 1 2 \left(X_{(n/2)} + X_{(n/2 + 1)} \right),& n为偶数 \end{cases} \quad \quad$，称其为 **样本中位数** 。

### 6.4 经验分布函数与直方图

#### 6.4.1 经验分布函数

假设总体 $X$ 的分布函数 $F(x)$ 未知，$x_1,x_2,\dots,x_n$ 是来自 $X$ 的一组样本值。将 $x_1,x_2,\dots,x_n$ 按从小到大的顺序排列，其结果记为 $x_{(1)} \leqslant x_{(2)} \leqslant \cdots \leqslant x_{(n)}$。对任意给定的一个实数 $x$，根据频率与概率的关系，得到

$$\begin{aligned} F(x) & = P\{X \leqslant x \} \\
       & \approx F_n\{X \leqslant x\} = \begin{cases} 0, & x < x_{(1)} \\ \dfrac k n, & x_{(k)} \leqslant x < x_{(k+1)},\quad k=1,2,\dots,n-1 \\ 1, & x \geqslant x{(n)} \end{cases} \end{aligned}$$

令

$$F_n(x) = \begin{cases} 0, & x < x_{(1)} \\ \dfrac k n, & x_{(k)} \leqslant x < x_{(k+1)},\quad k=1,2,\dots,n-1 \\ 1, & x \geqslant x{(n)} \end{cases}$$

易看出，$F_n(x)$ 是 $x$ 的单调不减函数，称 $F_n(x)$ 为总体 $X$ 的 **经验分布函数** 。由不同的样本观测值得到的 $F_n(x)$ 是不同的，因此，它也是一个不含未知参数的样本的函数，是一个统计量。

我们可以用经验分布函数 $F_n(x)$ 来估计总体 $X$ 的分布函数 $F(x)$。

#### 6.4.2 直方图

当总体 $X$ 是一个连续型随机变量时，我们也可以利用样本值 $x_1,x_2,\dots,x_n$ 画出直方图作为总体的密度函数 $g(x)$ 的近似图形，因此，直方图方法是一种拟合密度函数曲线的方法。

直方图的构图原理是：

1. 将一个包含 $x_1,x_2,\dots,x_n$ 的有界区间 $[a,b]$ 分成若干个小区间：$[t_i,t_{i+1}),i=1,2,\dots,m$
2. 对每个小区间 $[t_i,t_{i+1})$ 上的密度函数曲线用一条水平线段拟合，这条水平线的高度是密度函数在该区间某点的函数值的估计值

令 $f_i$ 表示事件 $\{t_i < X \leqslant t_{i-1}\}$ 在 $n$ 次试验中发生的频率，那么小区间 $[t_i,t_{i+1})$ 上水平线段的高度值取为 $y_i = \dfrac{f_i}{t_{i+1} - t_i}$

构造直方图的具体步骤如下：

1. 

### 6.5 抽样分布

**统计量的分布称为抽样分布** 。以样本平均数为例，它是总体平均数的一个估计量，如果按照相同的样本容量，相同的抽样方式，反复地抽取样本，每次可以计算一个平均数，所有可能样本的平均数所形成的分布，就是样本平均数的抽样分布。

#### 6.5.1 常用抽样分布

**1. $\chi^2$ 分布（卡方分布）**

设 $X_1,X_2,\dots,X_n$ 为 $n$ 个相互独立且都服从标准正态分布 $N(0,1)$ 的随机向量，记 $\chi^2=\displaystyle \sum_{i=1}^n X_i^2$，则称统计量 $\chi^2$ 服从自由度为 $n$ 的 $\chi^2$ 分布，记为 $\chi^2 \sim \chi^2(n)$。可以证明，$\chi^2$ 分布的密度函数为

$$f(x) = \begin{cases}\dfrac 1 {2^{\frac n 2}\Gamma(\frac n 2)} x^{\frac n 2 - 1}e^{-\frac x 2}, & x > 0 \\ 0, & x \leqslant 0 \end{cases}$$

其中 $\Gamma(\alpha) = \displaystyle \int_0^{+\infty} x^{\alpha - 1} e^{-x} \mathrm dx$，$\chi^2$ 分布具有如下两个重要性质：

1. 设 $\chi^2 \sim \chi^2(n)$，则 $E\chi^2 = n, D\chi^2 = 2n$
2. （可加性）设 $\chi_1^2 \sim \chi^2(n_1), \chi_2^2 \sim \chi^2(n_2)$，且 $\chi_1^2$ 和 $\chi_2^2$ 相互独立，则 $\chi_1^2 + \chi_2^2 \sim \chi^2(n_1+n_2)$。

**2. $t$ 分布（卡方分布）**

设 $X \sim N(0,1), Y \sim \chi^2(n)$，且 $X$ 与 $Y$ 相互独立，记 $T=\dfrac X {\sqrt{Y/n} }$，则称 $T$ 的分布为自由度为 $n$ 的 $t$ 分布，记为 $T\sim t(n)$。可以证明，$T$ 的密度函数为

$$f(x) = \dfrac {\Gamma\left(\dfrac{n+1} 2\right)} {\sqrt{n \pi} \Gamma\left(\dfrac n 2\right)} \left(1+\dfrac {x^2} n\right)^{-\frac{n+1} 2}, \quad x\in \mathbf R$$

**3. $F$ 分布（卡方分布）**

设 $X\sim\chi^2(m),Y\sim\chi^2(n)$，且 $X$ 与 $Y$ 相互独立，记 $F=\dfrac{X/m}{Y/n}$，则称 $F$ 的分布为第一自由度是 $m$，第二自由度为 $n$ 的 $F$ 分布，记为 $F\sim F(m,n)$。可以证明，$F$ 的密度函数为



#### 6.5.2 抽样分布定理

抽样分布定理是假设检验和参数估计的理论基础。

设总体 $X\sim N(\mu,\sigma^2),X_1,X_2,\dots,X_n$ 为来自 $X$ 的样本，$\overline X,S^2$ 分别为样本均值和样本方差，则

1. $\overline X \sim N\left(\mu,\dfrac{\sigma^2} n \right)$ 或 $\dfrac{\overline X - \mu}\sigma \sqrt n \sim N(0,1)$
2. $\dfrac{(n-1)S^2}{\sigma^2} = \dfrac 1 {\sigma^2} \displaystyle \sum_{i=1}^n(X_i - \overline X)^2 \sim \chi^2(n-1)$
3. $\overline X$ 与 $S^2$ 相互独立

设总体 $X\sim N(\mu,\sigma^2),X_1,X_2,\dots,X_n$ 为来自 $X$ 的样本，$\overline X,S^2$ 分别为样本均值和样本方差，则

1. $\dfrac{\overline X - \mu} S \sqrt n \sim t(n-1)$
2. $ES^2 = \sigma^2, DS^2 = \dfrac{2\sigma^4}{n-1}$

#### 6.5.3 分位数

设 $X$ 是连续型随机变量，分布函数为 $F(x)$，密度函数为 $f(x)$，对给定的概率 $p$，如有实数 $v_p$，使得

$$F(v_p) = P\{X\leqslant v_p\} = \int_{-\infty}^{v_p} f(x) \mathrm dx = p$$

则称 $v_p$ 为随机变量 $X$ 的（下侧） $p$ 分位数。

将标准正态分布、$\chi^2$ 分布、$t$ 分布、$F$ 分布的分位数分别记为 $u_p,t_p(n),\chi_p^2(n),F_p(m,n)$。

## 7.参数估计

### 7.1 参数估计的基本概念

如果总体的分布形式是已知的，但它含有一个或多个未知参数，利用来自总体的样本信息估计这些未知参数的问题就是参数估计问题。参数的估计形式有两种，点估计和区间估计。

### 7.2 点估计

点估计的方法有很多，常用的方法有矩法、最大似然法、顺序统计量法和最小二乘法。

#### 7.2.1 矩法

#### 7.2.2 最大似然法

设 $\theta_1,\theta_2,\dots,\theta_k$ 是总体 $X$ 的未知参数，$\varTheta$ 是参数 $\theta_1,\theta_2,\dots,\theta_k$ 可能的取值范围，称为参数空间，$X_1,X_2,\dots,X_n$ 是来自总体 $X$ 的样本，$x_1,x_2,\dots,x_n$ 是样本的一个观测值。

1. 对给定的样本观测值 $x_1,x_2,\dots,x_n$，计算似然函数 $$L(\theta_1,\theta_2,\dots,\theta_k;x_1,x_2,\dots,x_n) = \begin{cases} \displaystyle \prod_{i=1}^n P\{X=x_i\}, & 当总体 X 是离散型时 \\ \displaystyle \prod_{i=1}^n f(x_i), & 当总体 X 是连续型时 \end{cases}$$
2. 求未知参数 $\theta_1,\theta_2,\dots,\theta_k$ 的最大似然估计值 $\hat \theta_l = \hat \theta_l(x_1,x_2,\dots,x_n),l=1,2,\dots,k$，即为 $\theta_1,\theta_2,\dots,\theta_k$ 在参数空间 $\varTheta$ 内让似然函数 $L(\theta_1,\theta_2,\dots,\theta_k;x_1,x_2,\dots,x_n)$ 达到最大值的解，也就是下列优化问题的解：$$\displaystyle \max_{(\theta_1,\theta_2,\dots,\theta_k) \in \varTheta} L(\theta_1,\theta_2,\dots,\theta_k;x_1,x_2,\dots,x_n) $$

因为似然函数 $L(\theta_1,\theta_2,\dots,\theta_k;x_1,x_2,\dots,x_n)$ 与对数似然函数 $\ln L(\theta_1,\theta_2,\dots,\theta_k;x_1,x_2,\dots,x_n)$ 在参数空间 $\varTheta$ 内同一点达到最大值，所以，$\theta_1,\theta_2,\dots,\theta_k$ 的最大似然估计值可以通过如下的最优化问题得到：

$$\displaystyle \max_{(\theta_1,\theta_2,\dots,\theta_k) \in \varTheta} \ln L(\theta_1,\theta_2,\dots,\theta_k;x_1,x_2,\dots,x_n) $$

对上式的求解，一般可以转化为求解下列似然方程（组）：

$$\dfrac{\partial \ln L(\theta_1,\theta_2,\dots,\theta_k;x_1,x_2,\dots,x_n)}{\partial \theta_l} = 0, \quad l=1,2,\dots,k$$



### 7.3 估计优劣的评价标准

### 7.4 区间估计

## 8.假设检验

### 8.1 假设检验的基本原理与步骤

### 8.2 参数假设检验

### 8.3 非参数假设检验
